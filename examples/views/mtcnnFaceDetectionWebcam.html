<!DOCTYPE html>
<html>
<head>
  <script src="face-api.js"></script>
  <script src="commons.js"></script>
  <script src="controller_dataset.js"></script>
  <script src="ui.js"></script>
  <script src="webcam.js"></script>
  <link rel="stylesheet" href="styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
  <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
</head>
<body>
  <div id="navbar"></div>
  <div class="center-content page-container">
    <h3>Talking Detector</h3>
    <div class="progress" id="loader">
      <div class="indeterminate"></div>
    </div>
    <div style="position: relative" class="margin">
      <video id="inputVideo" autoplay muted></video>
      <canvas id="overlay" />
    </div>
    <div class="row side-by-side">    
      
      <div class="panel-row panel-row-top">

        <div class="panel-cell panel-cell-left panel-cell-fill">
          <p class="help-text">
          Adding Sample <br/>
          </p>
        </div><!-- ./panel-cell -->

        <div class="panel-cell panel-cell-center">
          <div class="thumb-box">
            <div class="thumb-box-outer">
              <div class="thumb-box-inner">
                <canvas class="thumb" width=224 height=224 id="up-thumb"></canvas>
              </div>
              <button class="record-button" id="up"/><span>Add Sample</span></button>
            </div>
            <p>
              <span id="up-total">0</span> examples
            </p>
          </div>
        </div><!-- ./panel-cell -->

        <div class="panel-cell panel-cell-right panel-cell-fill">
        </div><!-- ./panel-cell -->

      </div><!-- /.panel-row -->
      <button id="recButton"></button>
      <div class="panel-row panel-row-top">

        <div class="panel-cell panel-cell-left panel-cell-fill">
          <p class="help-text">
          Adding Sample <br/>
          </p>
        </div><!-- ./panel-cell -->

        <div class="panel-cell panel-cell-center">
          <div class="thumb-box">
            <div class="thumb-box-outer">
              <div class="thumb-box-inner">
                <canvas class="thumb" width=224 height=224 id="down-thumb"></canvas>
              </div>
              <button class="record-button" id="down"/><span>Add Sample</span></button>
            </div>
            <p>
              <span id="down-total">0</span> examples
            </p>
          </div>
        </div><!-- ./panel-cell -->

        <div class="panel-cell panel-cell-right panel-cell-fill">
        </div><!-- ./panel-cell -->

      </div><!-- /.panel-row -->
    </div>

    <div class="controller-panels" id="controller">

      <div class="panel training-panel">
  
        <!-- Big buttons. -->
        <div class="panel-row big-buttons">
          <button id="train">
            <img width="66" height="66" src="./images/eject.svg" />
            <span id="train-status">TRAIN MODEL</span>
          </button>
          <button id="predict">
            <img width="66" height="66" src="./images/next.svg" />
            <span>PLAY</span>
          </button>
        </div><!-- /.panel-row -->
  
        <div class="panel-row params-webcam-row">
  
          <!-- Hyper params. -->
          <div class="hyper-params">
  
            <!-- Learning rate -->
            <div class="dropdown">
              <label>Learning rate</label>
              <div class="select">
                <select id="learningRate">
                  <option value="0.00001">0.00001</option>
                  <option selected value="0.0001">0.0001</option>
                  <option value="0.01">0.001</option>
                  <option value="0.03">0.003</option>
                </select>
              </div>
            </div>
  
            <!-- Batch size -->
            <div class="dropdown">
              <label>Batch size</label>
              <div class="select">
                <select id="batchSizeFraction">
                  <option value="0.05">0.05</option>
                  <option value="0.1">0.1</option>
                  <option selected value="0.4">0.4</option>
                  <option value="1">1</option>
                </select>
              </div>
            </div>
  
            <!-- Epochs -->
            <div class="dropdown">
              <label>Epochs</label>
              <div class="select">
                <select id="epochs">
                  <option value="10">10</option>
                  <option value="20">20</option>
                  <option selected value="40">40</option>
                </select>
              </div>
            </div>
  
            <!-- Hidden units -->
            <div class="dropdown">
              <label>Hidden units</label>
              <div class="select">
                <select id="dense-units">
                  <option value="10">10</option>
                  <option selected value="100">100</option>
                  <option value="200">200</option>
                </select>
              </div>
            </div>
  
          </div><!-- /.hyper-params -->
  
          <div class="webcam-box-outer">
            <div class="webcam-box-inner">
              <video autoplay playsinline muted id="webcam" width="224" height="224"></video>
            </div>
          </div>
  
        </div><!-- /.panel-row -->
      </div><!-- /.panel -->
    </div><!-- /#controller -->


  
    <div class="row side-by-side">
      <div class="row">
        <label for="minFaceSize">Minimum Face Size:</label>
        <input disabled value="50" id="minFaceSize" type="text" class="bold">
      </div>
      <button
        class="waves-effect waves-light btn"
        onclick="onDecreaseMinFaceSize()"
      >
        <i class="material-icons left">-</i>
      </button>
      <button
        class="waves-effect waves-light btn"
        onclick="onIncreaseMinFaceSize()"
      >
        <i class="material-icons left">+</i>
      </button>
    </div>
    <div class="row side-by-side">
      <div class="row">
        <label for="Threshold">Entropy Threshold:</label>
        <input disabled value="2" id="Threshold" type="text" class="bold">
      </div>
      <button
        class="waves-effect waves-light btn"
        onclick="onDecreaseThreshold()"
      >
        <i class="material-icons left">-</i>
      </button>
      <button
        class="waves-effect waves-light btn"
        onclick="onIncreaseThreshold()"
      >
        <i class="material-icons left">+</i>
      </button>
    </div>
    <div class="row side-by-side">
      <div class="row">
        <label for="uthr">Minimum Unit:</label>
        <input disabled value="0.020" id="uthr" type="text" class="bold">
      </div>
      <button
        class="waves-effect waves-light btn"
        onclick="onDecreaseuthr()"
      >
        <i class="material-icons left">-</i>
      </button>
      <button
        class="waves-effect waves-light btn"
        onclick="onIncreaseuthr()"
      >
        <i class="material-icons left">+</i>
      </button>
    </div>
    <div class="row side-by-side">
      <div class="row">
        <label for="time">Time:</label>
        <input disabled value="-" id="time" type="text" class="bold">
      </div>
      <div class="row">
        <label for="fps">Estimated Fps:</label>
        <input disabled value="-" id="fps" type="text" class="bold">
      </div>
    </div>
    <div class="row side-by-side">    
      <div class="row">
        <label for="left">Left:</label>
        <input disabled value="-" id="left" type="text" class="bold">
      </div>
      <div class="row">
        <label for="right">Right:</label>
        <input disabled value="-" id="right" type="text" class="bold">
      </div>
    </div>
    <div class="row side-by-side">    
      <div class="row">
        <label for="down">Down:</label>
        <input disabled value="-" id="down" type="text" class="bold">
      </div>
      <div class="row">
        <label for="en">Entropy:</label>
        <input disabled value="-" id="en" type="text" class="bold">
      </div>
    </div>   
  </div>

  <script>
    
    let modelLoaded = false
    let minFaceSize = 50
    let minConfidence = 0.85
    let forwardTimes = []
    let stop = false

    let bgColor = '#ffffff'
    let drawLines = false
   
    let pointQ = new Queue();
    let OFF = false
    let end_time = 0
    let TRAIN = true
    let mobilenet
    let model
    let label_time
    let NUM_CLASSES = 2
    let videoEl

    const controllerDataset = new ControllerDataset(2)

    navigator.getUserMedia = ( navigator.getUserMedia ||
                       navigator.webkitGetUserMedia ||
                       navigator.mozGetUserMedia ||
                       navigator.msGetUserMedia);

    
    
   
   
    async function onPlay() {
      console.log('onPlay()!')
      console.log(videoEl.paused)
      console.log(videoEl.ended)
      if(videoEl.paused || videoEl.ended || !modelLoaded)
      { 
        console.log('return false') 
        //return false
      }
      let start_time = new Date().getTime()
      console.log('###############In################')
      //const imgBuf = await fetchImage(uri)
      const { width, height } = faceapi.getMediaDimensions(videoEl)
      const canvas = $('#overlay').get(0)
      canvas.width = width
      canvas.height = height
          
      const mtcnnParams = {
        minFaceSize
      }
      //const { results, stats } = await faceapi.nets.mtcnn.forwardWithStats(videoEl, mtcnnParams)
      let img = faceapi.createCanvasFromMedia(videoEl)
      const results = await faceapi.mtcnn(img, mtcnnParams)
      console.log(results)
      
      let mtcnn_time = new Date().getTime()
      let lmk68_time = 0
      //updateTimeStats(stats.total)
      if(results.length!=0){
        locations = []
        flen = results.length
        for (i = 0; i<flen; i++)
        {
          results[i].faceDetection.box.height = results[i].faceDetection.box.height/2
          results[i].faceDetection.box.y = results[i].faceDetection.box.y + results[i].faceDetection.box.height
          locations.push(results[i].faceDetection)
        }
        //const faceTensors = (await faceapi.extractFaceTensors(videoEl, locations))
        const faceImgs = (await faceapi.extractFaces(img, locations))
      
        let label = 1
        ilen = faceImgs.length
        for(i=0;i<ilen;i++)
        {
          webcam = new Webcam(faceImgs[i]) 
          IMG = webcam.capture()
          img_resize = faceapi.tf.image.resizeBilinear(IMG, [224, 224])
          const activation = mobilenet.predict(img_resize);
          const predictions = model.predict(activation);
          const predictedClass = predictions.as1D().argMax();
          label = (await predictedClass.data())[0];
          predictedClass.dispose();
        }
        lmk68_time = new Date().getTime()
   
        
        checktime = new Date().getTime()
        if(checktime-end_time>1000){
          while(!pointQ.isEmpty())
          {pointQ.dequeue()}
        }
        pointQ.enqueue(label)
        
        if(pointQ.getLength()>3){
          pointQ.dequeue()
        }
    
        //if(pointQ.getLength()!=1 && LabelSilent(pointQ))
        if(label==0)
        {
          console.log('E*************Off**************E')
          off()
        }
        else
        {
          console.log('E*************On**************E')
          on()
        }
        
        
        if (results) {

           for (i = 0; i<flen; i++)
          {
            results[i].faceDetection.box.y = results[i].faceDetection.box.y - results[i].faceDetection.box.height
            results[i].faceDetection.box.height = results[i].faceDetection.box.height*2
          
          }

          results.forEach(({ faceDetection, faceLandmarks }) => {
            if (faceDetection.score < minConfidence) {
              return
            }
            faceapi.drawDetection('overlay', faceDetection.forSize(width, height))
            //faceapi.drawLandmarks('overlay', faceLandmarks.forSize(width, height), { lineWidth: 4, color: 'red' })
          })
        }
        end_time = new Date().getTime();
      }else if(!TRAIN){
        console.log('No Detect')
        off()
      }
     
      
      console.log((mtcnn_time - start_time) / 1000 + "sec");
      console.log((lmk68_time - mtcnn_time) / 1000 + "sec");
      console.log((end_time - start_time) / 1000 + "sec");
      console.log('################Out###############')
      if(stop)
        return false
     
      setTimeout(() => onPlay(videoEl))
    }

    function off(){
        if($('#recButton').hasClass('Rec')){
          $('#recButton').removeClass("Rec");
          $('#recButton').addClass("notRec");
        }
        OFF = true
    }
    function on(){
        if($('#recButton').hasClass('notRec')){
          $('#recButton').removeClass("notRec");
          $('#recButton').addClass("Rec");
        }
        OFF = false
    }
  
    function LabelSilent(Q, threshold){
      let i, j, t, tf, EN = 0
      let Qlen = Q.getLength()

      for(j = 0; j<Qlen;j++)
      {
        tf = Q.getitem(j)
        if(tf==1){
          return false
        }
      }
      return true
    }
    async function run() {
      await faceapi.loadMtcnnModel('/')
      await faceapi.loadFaceLandmarkModel('/')
      mobilenet = await loadMobilenet();

      modelLoaded = true
    

      //const videoEl = $('#inputVideo').get(0)
      videoEl = $('#inputVideo').get(0)
      init()

      navigator.getUserMedia(
        { video: {} },
        stream => videoEl.srcObject = stream,
        err => console.error(err)
      )

       

      $('#loader').hide()
      
      $('#recButton').addClass("Rec");

      $('#recButton').click(function(){
        if($('#recButton').hasClass('notRec')){
          $('#recButton').removeClass("notRec");
          $('#recButton').addClass("Rec");
        }
        else{
          $('#recButton').removeClass("Rec");
          $('#recButton').addClass("notRec");
        }
      });
      label_time = new Date().getTime()
      on()	
      console.log('model loaded.')
    }

    $(document).ready(function() {
      //renderNavBar('#navbar', 'mtcnn_face_detection_webcam')
      run()
    })

    function Queue(){
      var a=[],b=0;
      this.getLength=function(){return a.length-b};
      this.isEmpty=function(){return 0==a.length};
      this.enqueue=function(b){a.push(b)};
      this.dequeue=function(){if(0!=a.length){var c=a[b];2*++b>=a.length&&(a=a.slice(b),b=0);return c}};
      this.peek=function(){return 0<a.length?a[b]:void 0};
      this.getitem=function(i){if(i<a.length){return a[i]}};
    }
    
    async function loadMobilenet() {
      const mobilenet = await faceapi.tf.loadModel(
          'https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_0.25_224/model.json');

      // Return a model that outputs an internal activation.
      const layer = mobilenet.getLayer('conv_pw_13_relu');
      //console.log(tf.shape(layer));
      return faceapi.tf.model({inputs: mobilenet.inputs, outputs: layer.output});
    }
    /**
 * Sets up and trains the classifier.
 */
    async function train() {
      if (controllerDataset.xs == null) {
        throw new Error('Add some examples before training!');
      }

      // Creates a 2-layer fully connected model. By creating a separate model,
      // rather than adding layers to the mobilenet model, we "freeze" the weights
      // of the mobilenet model, and only train weights from the new model.
      model = faceapi.tf.sequential({
        layers: [
          // Flattens the input to a vector so we can use it in a dense layer. While
          // technically a layer, this only performs a reshape (and has no training
          // parameters).
          faceapi.tf.layers.flatten({inputShape: [7, 7, 256]}),
          // Layer 1
          faceapi.tf.layers.dense({
            units: getDenseUnits(),
            activation: 'relu',
            kernelInitializer: 'varianceScaling',
            useBias: true
          }),
          // Layer 2. The number of units of the last layer should correspond
          // to the number of classes we want to predict.
          faceapi.tf.layers.dense({
            units: NUM_CLASSES,
            kernelInitializer: 'varianceScaling',
            useBias: false,
            activation: 'softmax'
          })
        ]
      });

      // Creates the optimizers which drives training of the model.
      const optimizer = faceapi.tf.train.adam(getLearningRate());
      // We use categoricalCrossentropy which is the loss function we use for
      // categorical classification which measures the error between our predicted
      // probability distribution over classes (probability that an input is of each
      // class), versus the label (100% probability in the true class)>
      model.compile({optimizer: optimizer, loss: 'categoricalCrossentropy'});

      // We parameterize batch size as a fraction of the entire dataset because the
      // number of examples that are collected depends on how many examples the user
      // collects. This allows us to have a flexible batch size.
      const batchSize =
          Math.floor(controllerDataset.xs.shape[0] * getBatchSizeFraction());
      if (!(batchSize > 0)) {
        throw new Error(
            `Batch size is 0 or NaN. Please choose a non-zero fraction.`);
      }

      // Train the model! Model.fit() will shuffle xs & ys so we don't have to.
      model.fit(controllerDataset.xs, controllerDataset.ys, {
        batchSize,
        epochs: getEpochs(),
        callbacks: {
          onBatchEnd: async (batch, logs) => {
            trainStatus('Loss: ' + logs.loss.toFixed(5));
            await faceapi.tf.nextFrame();
          }
        }
      });
    }
    document.getElementById('train').addEventListener('click', async () => {
    trainStatus('Training...');
    await faceapi.tf.nextFrame();
    await faceapi.tf.nextFrame();
    isPredicting = false;
    train();
  });
  document.getElementById('predict').addEventListener('click', () => {
    //startPacman();
    //isPredicting = true;
    //predict();
    console.log('predict!')
    console.log(videoEl)
    TRAIN = false
    onPlay()
  });

  setExampleHandler(label => {
    faceapi.tf.tidy(() => {
        addNetExample(label)
    });
  });

  async function addNetExample(label)
  {
    const { width, height } = faceapi.getMediaDimensions(videoEl)
    const canvas = $('#overlay').get(0)
    canvas.width = width
    canvas.height = height
        
    const mtcnnParams = {
      minFaceSize
    }
    
    let img = faceapi.createCanvasFromMedia(videoEl)
    const results = await faceapi.mtcnn(img, mtcnnParams)
    console.log(results)
    
    if(results.length!=0){
      locations = []
      flen = results.length
      for (i = 0; i<flen; i++)
      {
        results[i].faceDetection.box.height = results[i].faceDetection.box.height/2
        results[i].faceDetection.box.y = results[i].faceDetection.box.y + results[i].faceDetection.box.height
        locations.push(results[i].faceDetection)
      }
      
      const faceImgs = (await faceapi.extractFaces(img, locations))
    
      ilen = faceImgs.length
      for(i=0;i<ilen;i++)
      {
        webcam = new Webcam(faceImgs[i]) 
        IMG = webcam.capture()
        img_resize = faceapi.tf.image.resizeBilinear(IMG, [224, 224])
        controllerDataset.addExample(mobilenet.predict(img_resize), label)

        drawThumb(img_resize, label);
      }
    
      for (i = 0; i<flen; i++)
      {
        results[i].faceDetection.box.y = results[i].faceDetection.box.y - results[i].faceDetection.box.height
        results[i].faceDetection.box.height = results[i].faceDetection.box.height*2
      }

      results.forEach(({ faceDetection, faceLandmarks }) => {
      if (faceDetection.score < minConfidence) {
        return
      }
      faceapi.drawDetection('overlay', faceDetection.forSize(width, height))
      })
      
    }else{
      addNetExample(label)
    }
  }

  //button
  function onIncreaseMinFaceSize() {
      minFaceSize = Math.min(faceapi.round(minFaceSize + 50), 300)
      $('#minFaceSize').val(minFaceSize)
    }

  function onDecreaseMinFaceSize() {
    minFaceSize = Math.max(faceapi.round(minFaceSize - 50), 50)
    $('#minFaceSize').val(minFaceSize)
  }

  function onIncreaseThreshold() {
    Enthr= Math.min((Enthr + 0.1), 5)
    //let textT = Math.round(Enthr*100) + '%'
    let textT = Math.round(Enthr*100)/100
    $('#Threshold').val(textT)
  }

  function onDecreaseThreshold() {
    Enthr= Math.max((Enthr - 0.1), 0.0)
    //let textT = Math.round(Enthr*100) + '%'
    let textT = Math.round(Enthr*100)/100
    $('#Threshold').val(textT)
  }
  function onIncreaseuthr() {
    uthr= Math.min((uthr + 0.001), 3)
    //let textT = Math.round(Enthr*100) + '%'
    let textT = Math.round(uthr*1000)/1000
    $('#uthr').val(textT)
  }

  function onDecreaseuthr() {
    uthr= Math.max((uthr - 0.001), 0.0)
    //let textT = Math.round(Enthr*100) + '%'
    let textT = Math.round(uthr*1000)/1000
    $('#uthr').val(textT)
  }
  function updateTimeStats(timeInMs) {
    forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30)
    const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length
    $('#time').val(`${Math.round(avgTimeInMs)} ms`)
    $('#fps').val(`${faceapi.round(1000 / avgTimeInMs)}`)
  }
  </script>
</body>
</html>